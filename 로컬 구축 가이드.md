# 로컬 구축 가이드

CV Monitor Dashboard를 로컬 환경에서 실행하기 위한 가이드입니다.

---

## 1. 사전 요구사항

| 항목 | 버전 | 비고 |
|------|------|------|
| Node.js | 18.x 이상 | `node -v`로 확인 |
| pnpm | 8.x 이상 | `npm install -g pnpm`으로 설치 |
| Chrome/Chromium | 최신 | 크롤러용 (Puppeteer가 자동 설치) |

---

## 2. 프로젝트 클론 및 의존성 설치

```bash
# 프로젝트 클론
git clone <repository-url>
cd pentacle-teazen-CV-Monitor-Dashboard

# 프론트엔드 의존성 설치
pnpm install

# 크롤러 API 의존성 설치
cd crawler-api
pnpm install
cd ..
```

---

## 3. 환경변수 설정

### 3.1 프론트엔드 (.env.local)

프로젝트 루트에 `.env.local` 파일을 생성합니다:

```bash
# .env.local

# ============================================================
# 로컬 개발 모드 (JSON 파일 기반 DB 사용)
# ============================================================
USE_MOCK_DATA=true

# ============================================================
# OpenAI API (AI 감정분석 기능 사용시)
# https://platform.openai.com/api-keys
# ============================================================
OPENAI_API_KEY=sk-your-openai-api-key

# ============================================================
# 크롤러 API 서버 주소
# ============================================================
CRAWLER_API_URL=http://localhost:3001
```

> **참고**: `USE_MOCK_DATA=true` 설정시 Supabase 없이 `.data/db.json` 파일로 데이터가 저장됩니다.

### 3.2 크롤러 API (.env)

`crawler-api/.env` 파일을 생성합니다:

```bash
# crawler-api/.env

PORT=3001
```

---

## 4. 서버 실행

**터미널 2개**를 열어 각각 실행합니다.

### 터미널 1: 프론트엔드 (Next.js)

```bash
# 프로젝트 루트에서
pnpm dev
```

- 접속: http://localhost:3000

### 터미널 2: 크롤러 API (Express + Puppeteer)

```bash
# crawler-api 폴더에서
cd crawler-api
pnpm dev
```

- 접속: http://localhost:3001

---

## 5. 동작 확인

### 5.1 대시보드 접속

브라우저에서 http://localhost:3000 접속

- 초기 상태에서는 데이터가 없으므로 빈 화면이 표시됩니다.

### 5.2 카테고리 생성

1. 좌측 사이드바에서 **아이템 관리** 클릭
2. 상단의 **카테고리 관리** 또는 직접 API 호출:

```bash
curl -X POST http://localhost:3000/api/categories \
  -H "Content-Type: application/json" \
  -d '{"name": "콤부차", "color": "#4ECDC4"}'
```

### 5.3 아이템 등록

1. **아이템 관리** 페이지에서 **+ 아이템 추가** 클릭
2. 네이버 스마트스토어/브랜드스토어 URL 입력
   - 예: `https://smartstore.naver.com/xxx/products/xxx`
   - 예: `https://brand.naver.com/xxx/products/xxx`
3. 메타데이터(상품명, 이미지, 가격)가 자동 추출됩니다.

### 5.4 리뷰 크롤링

1. 등록된 아이템의 **크롤링** 버튼 클릭
2. 크롤러가 네이버에서 리뷰를 수집합니다.
3. 수집된 리뷰는 **리뷰 조회** 페이지에서 확인

### 5.5 AI 감정분석

1. **리뷰 조회** 페이지에서 리뷰 선택
2. **AI 분석** 버튼 클릭
3. OpenAI가 긍정/부정/중립을 분류합니다.

> **주의**: OpenAI API 키가 필요합니다. 키가 없으면 분석 기능이 작동하지 않습니다.

---

## 6. 데이터 저장 위치

로컬 모드에서 모든 데이터는 다음 파일에 저장됩니다:

```
.data/db.json
```

### 데이터 구조

```json
{
  "categories": [...],
  "items": [...],
  "reviews": [...],
  "review_analysis": [...]
}
```

### 데이터 초기화

데이터를 초기화하려면 파일을 삭제하면 됩니다:

```bash
rm .data/db.json
```

---

## 7. 문제 해결

### 7.1 크롤러가 작동하지 않음

**증상**: 크롤링 버튼 클릭 후 에러 발생

**해결**:
1. 크롤러 서버가 실행 중인지 확인 (`http://localhost:3001`)
2. Puppeteer가 Chrome을 찾지 못하면:
   ```bash
   cd crawler-api
   npx puppeteer browsers install chrome
   ```

### 7.2 OpenAI 분석이 안됨

**증상**: AI 요약 생성 버튼이 작동하지 않음

**해결**:
1. `.env.local`에 `OPENAI_API_KEY` 설정 확인
2. API 키가 유효한지 확인 (https://platform.openai.com/api-keys)
3. 키가 없으면 fallback 통계만 표시됩니다.

### 7.3 포트 충돌

**증상**: "Port 3000 is already in use"

**해결**:
```bash
# 사용 중인 프로세스 확인
lsof -i :3000

# 프로세스 종료
kill -9 <PID>
```

### 7.4 데이터가 표시되지 않음

**증상**: 대시보드가 비어있음

**해결**:
1. 카테고리와 아이템을 먼저 등록해야 합니다.
2. 크롤링을 실행하여 리뷰를 수집해야 합니다.

---

## 8. API 테스트 (curl)

### 카테고리 목록 조회
```bash
curl http://localhost:3000/api/categories
```

### 아이템 목록 조회
```bash
curl http://localhost:3000/api/items
```

### 리뷰 목록 조회
```bash
curl http://localhost:3000/api/reviews
```

### 크롤러 상태 확인
```bash
curl http://localhost:3001/health
```

---

## 9. 프로덕션 배포시

로컬 개발이 완료되면 Supabase를 연동하여 실제 DB를 사용할 수 있습니다:

1. [Supabase](https://supabase.com)에서 프로젝트 생성
2. `supabase/schema.sql` 실행하여 테이블 생성
3. `.env.local`에서 Supabase 환경변수 설정:
   ```bash
   NEXT_PUBLIC_SUPABASE_URL=https://xxx.supabase.co
   NEXT_PUBLIC_SUPABASE_ANON_KEY=xxx
   SUPABASE_SERVICE_ROLE_KEY=xxx
   USE_MOCK_DATA=false  # 또는 삭제
   ```

---

## 10. 지원 플랫폼

| 플랫폼 | URL 패턴 | 상태 |
|--------|----------|------|
| 네이버 스마트스토어 | `smartstore.naver.com` | 지원 |
| 네이버 브랜드스토어 | `brand.naver.com` | 지원 |
| 쿠팡 | `coupang.com` | 미지원 |

---

## 문의

문제가 발생하면 GitHub Issues에 등록해주세요.
